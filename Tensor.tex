% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\author{}
\date{}

\begin{document}

\hypertarget{header-n913}{%
\section{Tensor}\label{header-n913}}

\hypertarget{header-n915}{%
\subsection{Data type}\label{header-n915}}

Everything is a tensor in pytorch.

\hypertarget{header-n917}{%
\subsubsection{How to denote string}\label{header-n917}}

There is no string type in pytorch, only create one by coding like:

One-hot: {[}0,1,0,0,1...{]}

Embedding: Word2vec, glove.

\hypertarget{header-n921}{%
\subsubsection{Data type in pytorch}\label{header-n921}}

\begin{longtable}[]{@{}llll@{}}
\toprule
Data type & dtype & CPU tensor & GPU tensor\tabularnewline
\midrule
\endhead
32-bit floating point & \texttt{torch.float32} or \texttt{torch.float} &
\textbf{\texttt{torch.FloatTensor}} &
\texttt{torch.cuda.FloatTensor}\tabularnewline
64-bit floating point & \texttt{torch.float64} or \texttt{torch.double}
& \texttt{torch.DoubleTensor} &
\texttt{torch.cuda.DoubleTensor}\tabularnewline
16-bit floating point 1 & \texttt{torch.float16} or \texttt{torch.half}
& \texttt{torch.HalfTensor} &
\texttt{torch.cuda.HalfTensor}\tabularnewline
16-bit floating point 2 & \texttt{torch.bfloat16} &
\texttt{torch.BFloat16Tensor} &
\texttt{torch.cuda.BFloat16Tensor}\tabularnewline
8-bit integer (unsigned) & \texttt{torch.uint8} &
\textbf{\texttt{torch.ByteTensor}} &
\texttt{torch.cuda.ByteTensor}\tabularnewline
8-bit integer (signed) & \texttt{torch.int8} & \texttt{torch.CharTensor}
& \texttt{torch.cuda.CharTensor}\tabularnewline
16-bit integer (signed) & \texttt{torch.int16} or \texttt{torch.short} &
\texttt{torch.ShortTensor} &
\texttt{torch.cuda.ShortTensor}\tabularnewline
32-bit integer (signed) & \texttt{torch.int32} or \texttt{torch.int} &
\textbf{\texttt{torch.IntTensor}} &
\texttt{torch.cuda.IntTensor}\tabularnewline
64-bit integer (signed) & \texttt{torch.int64} or \texttt{torch.long} &
\texttt{torch.LongTensor} &
\texttt{torch.cuda.LongTensor}\tabularnewline
Boolean & \texttt{torch.bool} & \texttt{torch.BoolTensor} &
\texttt{torch.cuda.BoolTensor}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{header-n978}{%
\subsubsection{Type check}\label{header-n978}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.}\BuiltInTok{type}\NormalTok{(dtype}\OperatorTok{=}\VariableTok{None}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Returns the type if \texttt{dtype} is not provided, else casts this
object to the specified type.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{isinstance}\NormalTok{(a, torch.FloatTensor)}
\end{Highlighting}
\end{Shaded}

Detects whether the type is correct. Returns a bool.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.cuda()}
\end{Highlighting}
\end{Shaded}

Moves a tensor to GPU.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.shape}
\end{Highlighting}
\end{Shaded}

Returns an object like 'torch.Size({[}d1,d2,...{]})'. Use
\texttt{a.shape{[}x{]}} to return the value of Index{[}x{]}.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(a.shape)}
\end{Highlighting}
\end{Shaded}

Returns the dimension, like a is a 2-D tensor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.size()}
\end{Highlighting}
\end{Shaded}

Calls a function to return the size. Use \texttt{a.size(x)} to return
the value of Index{[}x{]}.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(a.shape)}
\end{Highlighting}
\end{Shaded}

Turns a shape to a list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.numel()}
\end{Highlighting}
\end{Shaded}

Returns the total number of elements.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a.dom()}
\end{Highlighting}
\end{Shaded}

Returns the dimension.

\hypertarget{header-n997}{%
\subsection{Creating}\label{header-n997}}

\hypertarget{header-n1076}{%
\subsubsection{Keyword Arguments}\label{header-n1076}}

\texttt{dtype}: Desires data type. If None, uses a global default.

\texttt{size}(tuple): defines the shape of the output tensor.

\hypertarget{header-n1089}{%
\subsubsection{\texorpdfstring{API }{API  }}\label{header-n1089}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.from\_numpy()}
\end{Highlighting}
\end{Shaded}

Turns an array to a tensor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.tensor(data,dtype}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Returns a tensor with pre-existing data. The tensor's \texttt{dtype} is
inferred from \texttt{data}.

tensor(1): creates a 0-D tensor with one element.

tensor({[}{[}1{]}{]}): creates a 2-D tensor with one element.

\texttt{dtype}: If None, infers data type from \texttt{data}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.Tensor(}\OperatorTok{*}\NormalTok{sizes)}
\end{Highlighting}
\end{Shaded}

Returns a tensor with specific \texttt{size}, using the column 3,4 in
the data type tabular. The data is uninitialized.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.set\_default\_tensor\_type(torch.DoubleTensor)}
\end{Highlighting}
\end{Shaded}

Changes the default type, which is \texttt{torch.float} before.

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{*}\NormalTok{\_like(}\BuiltInTok{input}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Returns a tensor with the same size as \texttt{input}, like
\texttt{torch.rand\_like}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.rand(}\OperatorTok{*}\NormalTok{size,dtype}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Returns a tensor filled with random numbers from a uniform distribution
on {[}0,1).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.randint(low}\OperatorTok{=}\DecValTok{0}\NormalTok{, high, size)}
\end{Highlighting}
\end{Shaded}

Returns a tensor filled with random integers generated uniformly on
{[}\texttt{low},\texttt{high}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.randn(}\OperatorTok{*}\NormalTok{size)}
\end{Highlighting}
\end{Shaded}

Returns a tensor filled with random numbers from a normal distribution
with mean 0 and variance 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.full(size, fill\_value)}
\end{Highlighting}
\end{Shaded}

Creates a tensor of \texttt{size} filled with \texttt{fill\_value}. The
tensor's \texttt{dtype} is inferred from \texttt{fill\_value}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.arange(start}\OperatorTok{=}\DecValTok{0}\NormalTok{, end, step}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Returns a 1-D tensor with values from {[}start, end) taken with common
difference \texttt{step} beginning from start.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.linspace(start, end, steps)}
\end{Highlighting}
\end{Shaded}

Returns a 1-D tensor of size \texttt{steps} whose values are evenly
spaced from {[}start, end{]} .

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.ones}\OperatorTok{/}\NormalTok{zeros(}\OperatorTok{*}\NormalTok{size)}
\end{Highlighting}
\end{Shaded}

Returns a tensor filled with the scalar value 1/0.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.eye(n, m}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.

n(int): the number of rows, m(int): the number of columns with default
n.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.randperm(n)}
\end{Highlighting}
\end{Shaded}

Returns a random permutation of integers from \texttt{0} to
\texttt{n\ -\ 1}.

Use this to create a random index.

\hypertarget{header-n1158}{%
\subsection{Indexing}\label{header-n1158}}

\hypertarget{header-n1154}{%
\subsubsection{Slice operation}\label{header-n1154}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[m1:n1:s1,m2:n2:s2,…]}
\end{Highlighting}
\end{Shaded}

For each dimension, index from m, to n( not included) with step s.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[d1,...,d2]}
\end{Highlighting}
\end{Shaded}

\texttt{...}means\texttt{:\ ,\ :\ ,\ :\ ···}, the number of dimension
\texttt{...}represents will get automatically.

\hypertarget{header-n1181}{%
\subsubsection{API}\label{header-n1181}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.index\_select(}\BuiltInTok{input}\NormalTok{, dim, index)}
\end{Highlighting}
\end{Shaded}

Returns a new tensor which indexes the \texttt{input} tensor along
dimension \texttt{dim} using the index in \texttt{index} which is a
LongTensor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.masked\_select(}\BuiltInTok{input}\NormalTok{, mask)}
\end{Highlighting}
\end{Shaded}

Returns a new 1-D tensor which indexes the \texttt{input} tensor
according to \texttt{mask} which is a BoolTensor.

The shapes of the \texttt{mask} tensor and the \texttt{input} tensor
don't need to match, but they must be broadcastable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}python}

\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\hypertarget{header-n1209}{%
\subsection{Comparing}\label{header-n1209}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.ge(}\BuiltInTok{input}\NormalTok{, other)}
\end{Highlighting}
\end{Shaded}

Computes input ≥ other element-wise.

\texttt{other}: can be a number or a tensor and the shapes of
\texttt{other} and \texttt{input} don't need to match, but they must be
broadcastable.

\hypertarget{header-n1022}{%
\paragraph{view(*args)}\label{header-n1022}}

返回一个有相同数据但大小不同的tensor，参数中允许有一个-1，系统将自动计算该值，使得参数连乘等于原Tensor元素相同。

\end{document}
